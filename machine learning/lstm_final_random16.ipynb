{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a383f74d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abb9a00",
   "metadata": {},
   "source": [
    "## Read data file and some glimpse on raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea977cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are ther any Nan value?:\n",
      " Strain               False\n",
      "Stress               False\n",
      "Strain Rate          False\n",
      "Temperature          False\n",
      "Normalized Stress    False\n",
      "dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strain</th>\n",
       "      <th>Stress</th>\n",
       "      <th>Strain Rate</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Normalized Stress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>580.282200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>298.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0004</td>\n",
       "      <td>644.631000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>298.0</td>\n",
       "      <td>1.110892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0006</td>\n",
       "      <td>681.693300</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>298.0</td>\n",
       "      <td>1.174762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0008</td>\n",
       "      <td>706.112533</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>298.0</td>\n",
       "      <td>1.216843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>727.073400</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>298.0</td>\n",
       "      <td>1.252965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Strain      Stress  Strain Rate  Temperature  Normalized Stress\n",
       "1  0.0002  580.282200       0.0001        298.0           1.000000\n",
       "2  0.0004  644.631000       0.0001        298.0           1.110892\n",
       "3  0.0006  681.693300       0.0001        298.0           1.174762\n",
       "4  0.0008  706.112533       0.0001        298.0           1.216843\n",
       "5  0.0010  727.073400       0.0001        298.0           1.252965"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"experiment_data_lstm.csv\"\n",
    "df = pd.read_csv(filename, header=0, sep=',', dtype=np.float64)\n",
    "print('Are ther any Nan value?:\\n', np.isnan(df).any())\n",
    "# ignore rows which contain zero\n",
    "# ignore rows which have negative instantaneous rate\n",
    "ignore_zero = df[(df['Strain']==0) | (df['Stress']==0) | (df['Temperature']==0) | (df['Strain Rate']<=0) ]\n",
    "df=pd.concat([df, ignore_zero, ignore_zero]).drop_duplicates(keep=False)\n",
    "df=pd.concat([df, ignore_zero, ignore_zero]).drop_duplicates(keep=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eef733",
   "metadata": {},
   "source": [
    "## Splitting flow curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55a061b",
   "metadata": {},
   "source": [
    "The individual flow curves are stacked one after the other in the csv file, so they need to be split according to the strain rate and temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3e79fb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Flow curves in different strain rates at RT\n",
    "df_e4 = df[(df['Strain Rate']==0.0001) & (df['Temperature']==298.0)]\n",
    "df_e3 = df[(df['Strain Rate']==0.001) & (df['Temperature']==298.0)]\n",
    "df_e2 = df[(df['Strain Rate']==0.01) & (df['Temperature']==298.0)]\n",
    "df_e1 = df[(df['Strain Rate']==0.1) & (df['Temperature']==298.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c887921d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Flow curves in 0.1 strain rate at varying T\n",
    "df_e1_373K = df[(df['Strain Rate']==0.1) & (df['Temperature']==373.0)]\n",
    "df_e1_473K = df[(df['Strain Rate']==0.1) & (df['Temperature']==473.0)]\n",
    "df_e1_573K = df[(df['Strain Rate']==0.1) & (df['Temperature']==573.0)]\n",
    "df_e1_673K = df[(df['Strain Rate']==0.1) & (df['Temperature']==673.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb2322cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Flow curves in 0.01 strain rate at varying T\n",
    "df_e2_373K = df[(df['Strain Rate']==0.01) & (df['Temperature']==373.0)]\n",
    "df_e2_473K = df[(df['Strain Rate']==0.01) & (df['Temperature']==473.0)]\n",
    "df_e2_573K = df[(df['Strain Rate']==0.01) & (df['Temperature']==573.0)]\n",
    "df_e2_673K = df[(df['Strain Rate']==0.01) & (df['Temperature']==673.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42f093e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Flow curves in 0.001 strain rate at varying T\n",
    "df_e3_373K = df[(df['Strain Rate']==0.001) & (df['Temperature']==373.0)]\n",
    "df_e3_473K = df[(df['Strain Rate']==0.001) & (df['Temperature']==473.0)]\n",
    "df_e3_573K = df[(df['Strain Rate']==0.001) & (df['Temperature']==573.0)]\n",
    "df_e3_673K = df[(df['Strain Rate']==0.001) & (df['Temperature']==673.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3c68b2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Flow curves in 0.0001 strain rate at varying T\n",
    "df_e4_373K = df[(df['Strain Rate']==0.0001) & (df['Temperature']==373.0)]\n",
    "df_e4_473K = df[(df['Strain Rate']==0.0001) & (df['Temperature']==473.0)]\n",
    "df_e4_573K = df[(df['Strain Rate']==0.0001) & (df['Temperature']==573.0)]\n",
    "df_e4_673K = df[(df['Strain Rate']==0.0001) & (df['Temperature']==673.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48985eb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of e4_298K: (241, 5)\n",
      "Shape of e4_373K: (528, 5)\n",
      "Shape of e4_473K: (567, 5)\n",
      "Shape of e4_573K: (468, 5)\n",
      "Shape of e4_673K: (512, 5)\n",
      "Shape of e3_298K: (234, 5)\n",
      "Shape of e3_373K: (526, 5)\n",
      "Shape of e3_473K: (607, 5)\n",
      "Shape of e3_573K: (772, 5)\n",
      "Shape of e3_673K: (596, 5)\n",
      "Shape of e2_298K: (94, 5)\n",
      "Shape of e2_373K: (552, 5)\n",
      "Shape of e2_473K: (533, 5)\n",
      "Shape of e2_573K: (691, 5)\n",
      "Shape of e2_673K: (579, 5)\n",
      "Shape of e1_298K: (48, 5)\n",
      "Shape of e1_373K: (61, 5)\n",
      "Shape of e1_473K: (45, 5)\n",
      "Shape of e1_573K: (64, 5)\n",
      "Shape of e1_673K: (64, 5)\n"
     ]
    }
   ],
   "source": [
    "# Put all flow curves in a dictionary for easy access \n",
    "flows = {'e4_298K': df_e4,\n",
    "         'e4_373K': df_e4_373K,\n",
    "         'e4_473K': df_e4_473K,\n",
    "         'e4_573K': df_e4_573K,\n",
    "         'e4_673K': df_e4_673K,\n",
    "         'e3_298K': df_e3,\n",
    "         'e3_373K': df_e3_373K,\n",
    "         'e3_473K': df_e3_473K,\n",
    "         'e3_573K': df_e3_573K,\n",
    "         'e3_673K': df_e3_673K,\n",
    "         'e2_298K': df_e2,\n",
    "         'e2_373K': df_e2_373K,\n",
    "         'e2_473K': df_e2_473K,\n",
    "         'e2_573K': df_e2_573K,\n",
    "         'e2_673K': df_e2_673K,\n",
    "         'e1_298K': df_e1,\n",
    "         'e1_373K': df_e1_373K,\n",
    "         'e1_473K': df_e1_473K,\n",
    "         'e1_573K': df_e1_573K,\n",
    "         'e1_673K': df_e1_673K\n",
    "        }\n",
    "# Iterate through the flows dictionary and print the shape of each DataFrame\n",
    "for key, df in flows.items():\n",
    "    print(f\"Shape of {key}: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1488ca0",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdd0d5c",
   "metadata": {},
   "source": [
    "In this section, the data is first normalised, then split into train-test data, and finally split into features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "345277f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['log_strain', 'log_rate', 'Temperature', 'Stress',\n",
       "       'Normalized Stress'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, logarithm is applied to strain and strain rate before normalising.\n",
    "\n",
    "flows_log = {}\n",
    "for key, fc in flows.items():\n",
    "    fc = fc.reset_index(drop=True)\n",
    "    # apply decadic log to strain rates\n",
    "    log_rate = pd.DataFrame(np.log10(fc['Strain Rate'].values))\n",
    "    log_rate.columns = ['log_rate']\n",
    "    # apply decadic log to strain\n",
    "    log_strain = pd.DataFrame(np.log10(fc['Strain'].values))\n",
    "    log_strain.columns = ['log_strain']\n",
    "    \n",
    "    fc_log = pd.concat([fc, log_strain, log_rate], axis=1)\n",
    "    fc_log = fc_log.drop(columns=['Strain', 'Strain Rate'])\n",
    "    cols = ['log_strain', 'log_rate', 'Temperature', 'Stress', 'Normalized Stress']\n",
    "    fc_log = fc_log[cols]\n",
    "    flows_log[key] = fc_log\n",
    "raw_features = len(flows_log['e4_298K'].columns.values)\n",
    "flows_log['e4_298K'].columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cd964b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_strain</th>\n",
       "      <th>log_rate</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Stress</th>\n",
       "      <th>Normalized Stress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.400637</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.111441</td>\n",
       "      <td>571.162231</td>\n",
       "      <td>0.036753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.434085</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.111441</td>\n",
       "      <td>579.519959</td>\n",
       "      <td>0.045409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.367190</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.111441</td>\n",
       "      <td>587.720642</td>\n",
       "      <td>0.053902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.356422</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.111441</td>\n",
       "      <td>595.775391</td>\n",
       "      <td>0.062244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.381072</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.111441</td>\n",
       "      <td>603.783569</td>\n",
       "      <td>0.070537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   log_strain  log_rate  Temperature      Stress  Normalized Stress\n",
       "0    0.400637      0.75     0.111441  571.162231           0.036753\n",
       "1    0.434085      0.75     0.111441  579.519959           0.045409\n",
       "2    0.367190      0.75     0.111441  587.720642           0.053902\n",
       "3    0.356422      0.75     0.111441  595.775391           0.062244\n",
       "4    0.381072      0.75     0.111441  603.783569           0.070537"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalise the data according to the min-max formula\n",
    "\n",
    "flows_scaled = {}\n",
    "#stress_range = np.array([40, 570])\n",
    "#temp_range = np.array([290, 700])\n",
    "# Get the range for Stress\n",
    "stress_min = df['Normalized Stress'].min()\n",
    "stress_max = df['Normalized Stress'].max()\n",
    "stress_range = np.array([stress_min, stress_max])\n",
    "\n",
    "# Get the range for Temp (Temperature)\n",
    "temp_min = df['Temperature'].min()\n",
    "temp_max = df['Temperature'].max()\n",
    "temp_range = np.array([298,673])\n",
    "\n",
    "log_strain_range = [np.log10(0.08068), np.log10(1e-9)] # valid only if strain < 1.0\n",
    "log_rate_range = [np.log10(0.1), np.log10(0.0001)] # valid only if rate < 1.0\n",
    "\n",
    "def manual_scaling(feat, range_value):\n",
    "    return (feat - range_value[0])/range_value[1]\n",
    "def manual_descaling(feat, range_value): # inverse of the function above\n",
    "    return feat * range_value[1] + range_value[0]\n",
    "\n",
    "for key, fc in flows_log.items():\n",
    "    fc['Normalized Stress'] = manual_scaling(fc['Normalized Stress'], stress_range)\n",
    "    fc['Temperature'] = manual_scaling(fc['Temperature'], temp_range)\n",
    "    fc['log_strain'] = manual_scaling(fc['log_strain'], log_strain_range)\n",
    "    fc['log_rate'] = manual_scaling(fc['log_rate'], log_rate_range)\n",
    "    flows_scaled[key] = fc\n",
    "flows_scaled['e4_373K'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4766c7",
   "metadata": {},
   "source": [
    "## Decompose train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53cc987f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set: ['e4_473K', 'e3_373K', 'e2_298K', 'e1_573K']\n",
      "Train Set: ['e4_298K', 'e4_373K', 'e4_573K', 'e4_673K', 'e3_298K', 'e3_473K', 'e3_573K', 'e3_673K', 'e2_373K', 'e2_473K', 'e2_573K', 'e2_673K', 'e1_298K', 'e1_373K', 'e1_473K', 'e1_673K']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "train_set_name = ['e4_298K', 'e4_373K', 'e4_573K', 'e4_673K', \n",
    "                  'e3_373K', 'e3_473K', 'e3_573K', 'e3_673K',\n",
    "                  'e2_298K', 'e2_473K','e2_573K', 'e2_673K', \n",
    "                  'e1_298K', 'e1_373K', 'e1_473K', 'e1_673K']\n",
    "test_set_name = ['e4_473K',\n",
    "                 'e3_298K', \n",
    "                 'e2_373K', \n",
    "                 'e1_573K']\n",
    "'''\n",
    "import random\n",
    "\n",
    "# Group keys by their prefixes (e4, e3, e2, e1)\n",
    "groups = {\n",
    "    'e4': [key for key in flows_scaled.keys() if key.startswith('e4')],\n",
    "    'e3': [key for key in flows_scaled.keys() if key.startswith('e3')],\n",
    "    'e2': [key for key in flows_scaled.keys() if key.startswith('e2')],\n",
    "    'e1': [key for key in flows_scaled.keys() if key.startswith('e1')]\n",
    "}\n",
    "\n",
    "# Ensure test set includes one key per group with unique temperatures\n",
    "selected_temperatures = set()\n",
    "test_set_name = []\n",
    "\n",
    "for group in groups:\n",
    "    group_keys = groups[group]\n",
    "    valid_keys = [key for key in group_keys if key.split('_')[-1] not in selected_temperatures]\n",
    "    \n",
    "    if valid_keys:  # If there are keys with unselected temperatures\n",
    "        chosen_key = random.choice(valid_keys)\n",
    "        selected_temperatures.add(chosen_key.split('_')[-1])\n",
    "        test_set_name.append(chosen_key)\n",
    "    else:\n",
    "        # Fallback to random choice if no unique temperature is left\n",
    "        test_set_name.append(random.choice(group_keys))\n",
    "\n",
    "# The remaining keys will be used for the training set\n",
    "train_set_name = [key for key in flows_scaled.keys() if key not in test_set_name]\n",
    "\n",
    "# Output the results\n",
    "print(\"Test Set:\", test_set_name)\n",
    "print(\"Train Set:\", train_set_name)\n",
    "\n",
    "train_set = []\n",
    "test_set = []\n",
    "val_set = []\n",
    "exp_no_T = []\n",
    "\n",
    "for key, fc in flows_scaled.items():\n",
    "    if key in train_set_name:\n",
    "        train_set.append(fc)\n",
    "    if key in test_set_name:\n",
    "        test_set.append(fc)\n",
    "    else:\n",
    "        exp_no_T.append(fc)\n",
    "        \n",
    "df_train = pd.concat(train_set)\n",
    "df_test = pd.concat(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65a5d790",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['e4_298K', 'e4_373K', 'e4_473K', 'e4_573K', 'e4_673K', 'e3_298K', 'e3_373K', 'e3_473K', 'e3_573K', 'e3_673K', 'e2_298K', 'e2_373K', 'e2_473K', 'e2_573K', 'e2_673K', 'e1_298K', 'e1_373K', 'e1_473K', 'e1_573K', 'e1_673K'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flows_scaled.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3970701",
   "metadata": {},
   "source": [
    "## Decompose label and feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fac9a85d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original columns: \n",
      "\n",
      " ['log_strain', 'log_rate', 'Temperature', 'Stress', 'Normalized Stress'] \n",
      "\n",
      "Label column... ['Normalized Stress'] \n",
      "\n",
      "Ignore columns... ['Stress'] \n",
      "\n",
      "X_train shape: (6531, 3)\n",
      "y_train shape: (6531, 1)\n",
      "X_test shape: (1251, 3)\n",
      "y_test shape: (1251, 1)\n",
      "X_test shape for set e4_473K (567, 3)\n",
      "y_test shape for set e4_473K (567, 1)\n",
      "X_test shape for set e3_373K (526, 3)\n",
      "y_test shape for set e3_373K (526, 1)\n",
      "X_test shape for set e2_298K (94, 3)\n",
      "y_test shape for set e2_298K (94, 1)\n",
      "X_test shape for set e1_573K (64, 3)\n",
      "y_test shape for set e1_573K (64, 1)\n",
      "X_train shape for set e4_298K (241, 3)\n",
      "y_train shape for set e4_298K (241, 1)\n",
      "X_train shape for set e4_373K (528, 3)\n",
      "y_train shape for set e4_373K (528, 1)\n",
      "X_train shape for set e4_573K (468, 3)\n",
      "y_train shape for set e4_573K (468, 1)\n",
      "X_train shape for set e4_673K (512, 3)\n",
      "y_train shape for set e4_673K (512, 1)\n",
      "X_train shape for set e3_298K (234, 3)\n",
      "y_train shape for set e3_298K (234, 1)\n",
      "X_train shape for set e3_473K (607, 3)\n",
      "y_train shape for set e3_473K (607, 1)\n",
      "X_train shape for set e3_573K (772, 3)\n",
      "y_train shape for set e3_573K (772, 1)\n",
      "X_train shape for set e3_673K (596, 3)\n",
      "y_train shape for set e3_673K (596, 1)\n",
      "X_train shape for set e2_373K (552, 3)\n",
      "y_train shape for set e2_373K (552, 1)\n",
      "X_train shape for set e2_473K (533, 3)\n",
      "y_train shape for set e2_473K (533, 1)\n",
      "X_train shape for set e2_573K (691, 3)\n",
      "y_train shape for set e2_573K (691, 1)\n",
      "X_train shape for set e2_673K (579, 3)\n",
      "y_train shape for set e2_673K (579, 1)\n",
      "X_train shape for set e1_298K (48, 3)\n",
      "y_train shape for set e1_298K (48, 1)\n",
      "X_train shape for set e1_373K (61, 3)\n",
      "y_train shape for set e1_373K (61, 1)\n",
      "X_train shape for set e1_473K (45, 3)\n",
      "y_train shape for set e1_473K (45, 1)\n",
      "X_train shape for set e1_673K (64, 3)\n",
      "y_train shape for set e1_673K (64, 1)\n"
     ]
    }
   ],
   "source": [
    "lbl_name = ['Normalized Stress']\n",
    "\n",
    "ignore_cols = ['Stress']\n",
    "\n",
    "def decomp_label_feat(df, lbl_col, ignore_cols=[]):\n",
    "    label = pd.DataFrame(df[lbl_col])\n",
    "    ignore_cols.append(lbl_col[0])\n",
    "    feat = df.drop(columns=ignore_cols)\n",
    "    return feat.values, label.values\n",
    "\n",
    "def restore_strain(log_strain_col, range_value):\n",
    "    log_strain = manual_descaling(log_strain_col, log_strain_range)\n",
    "    return 10**log_strain\n",
    "\n",
    "print('Original columns: \\n\\n',cols,'\\n')\n",
    "print('Label column...', lbl_name, '\\n')\n",
    "print('Ignore columns...', ignore_cols, '\\n')\n",
    "\n",
    "\n",
    "X_train, y_train = decomp_label_feat(df_train, lbl_name, ignore_cols)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "X_test, y_test = decomp_label_feat(df_test, lbl_name, ignore_cols)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "\n",
    "# Organise the training and testing flow curves into their respective dictionaries for easy access\n",
    "X_test_dict = {}\n",
    "y_test_dict = {}\n",
    "for ii, df_test in enumerate(test_set):\n",
    "    X_test_dict[test_set_name[ii]], y_test_dict[test_set_name[ii]] = decomp_label_feat(df_test, lbl_name, ignore_cols)\n",
    "    print('X_test shape for set ' + test_set_name[ii], X_test_dict[test_set_name[ii]].shape)\n",
    "    print('y_test shape for set ' + test_set_name[ii], y_test_dict[test_set_name[ii]].shape)\n",
    "\n",
    "X_train_dict = {}\n",
    "y_train_dict = {}\n",
    "for jj, df_train in enumerate(train_set):\n",
    "    X_train_dict[train_set_name[jj]], y_train_dict[train_set_name[jj]] = decomp_label_feat(df_train, lbl_name, ignore_cols)\n",
    "    print('X_train shape for set ' + train_set_name[jj], X_train_dict[train_set_name[jj]].shape)\n",
    "    print('y_train shape for set ' + train_set_name[jj], y_train_dict[train_set_name[jj]].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12028a8",
   "metadata": {},
   "source": [
    "## Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a415eefe-35af-460b-88d0-147afc483667",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: scikeras in /users/lehoang1/.local/lib/python3.9/site-packages (0.13.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in /users/lehoang1/.local/lib/python3.9/site-packages (from scikeras) (3.6.0)\n",
      "Requirement already satisfied: scikit-learn>=1.4.2 in /users/lehoang1/.local/lib/python3.9/site-packages (from scikeras) (1.5.2)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/site-packages (from keras>=3.2.0->scikeras) (2.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib64/python3.9/site-packages (from keras>=3.2.0->scikeras) (1.26.4)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.9/site-packages (from keras>=3.2.0->scikeras) (13.7.1)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.9/site-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib64/python3.9/site-packages (from keras>=3.2.0->scikeras) (3.11.0)\n",
      "Requirement already satisfied: optree in /users/lehoang1/.local/lib/python3.9/site-packages (from keras>=3.2.0->scikeras) (0.13.0)\n",
      "Requirement already satisfied: ml-dtypes in /usr/local/lib64/python3.9/site-packages (from keras>=3.2.0->scikeras) (0.3.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/site-packages (from keras>=3.2.0->scikeras) (24.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib64/python3.9/site-packages (from scikit-learn>=1.4.2->scikeras) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.9/site-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.9/site-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/site-packages (from rich->keras>=3.2.0->scikeras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44c2369b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 13:14:43.957586: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-19 13:14:43.976692: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-19 13:14:43.999866: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-19 13:14:44.006986: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-19 13:14:44.025965: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-19 13:14:45.210469: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12e0be31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0fe06b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sLSTMmodel(input_shape, nNeurons_1=150, nNeurons_2=370, nNeurons_3=370, out_dim=1):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(nNeurons_1, input_shape=input_shape, activation='relu', return_sequences=True))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(LSTM(nNeurons_2, input_shape=input_shape, activation='relu', return_sequences=True))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(LSTM(nNeurons_3, input_shape=input_shape, activation='relu', return_sequences=True))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(out_dim))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ecdabd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning \n",
    "# Keep runLSTM as True if you want to perform the hyperparameter tuning\n",
    "runLSTM = False\n",
    "np.random.seed(157)\n",
    "n_iter = 10\n",
    "param_dist = {\n",
    "    'model__nNeurons_1': range(10, 300, 20),\n",
    "    'model__nNeurons_2': range(10, 500, 20),\n",
    "    'model__nNeurons_3': range(10, 500, 20)\n",
    "}\n",
    "\n",
    "X_train_lstm = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "if runLSTM:\n",
    "    slstm = KerasRegressor(model=sLSTMmodel, input_shape=X_train_lstm.shape[1:], epochs=50, batch_size=32, verbose=0)\n",
    "    random_search_slstm = RandomizedSearchCV(estimator=slstm, param_distributions=param_dist, scoring='r2')\n",
    "    start = time.time()\n",
    "    random_search_slstm.fit(X_train_lstm, y_train)\n",
    "    elapsed_lstm = (time.time() - start)\n",
    "    print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "          \" parameter settings.\" % (elapsed_lstm, n_iter))\n",
    "    report(random_search_slstm.cv_results_)\n",
    "\n",
    "# This will output the 3 best models along with the time taken to complete the hyperparameter tuning.\n",
    "# It is best to run this using GPUs on CSC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0615553f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 13:14:46.513804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31141 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0\n",
      "/users/lehoang1/.local/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1734606891.790277 3389785 service.cc:146] XLA service 0x561a38864050 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1734606891.790305 3389785 service.cc:154]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-12-19 13:14:51.890452: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-19 13:14:52.474165: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "I0000 00:00:1734606893.393520 3389785 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score for training set: 0.993913022232035\n",
      "r2_score for testing set: 0.9831200659950813\n",
      "Stack LSTM took 24.51 seconds for test.\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "runLSTM = False\n",
    "X_train_lstm = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_lstm = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "if runLSTM:\n",
    "    best_slstm = random_search_slstm.best_estimator_\n",
    "else:\n",
    "    best_slstm_param =  {'nNeurons_3': 370, 'nNeurons_2': 370, 'nNeurons_1': 150}\n",
    "    best_slstm = KerasRegressor(model=sLSTMmodel, input_shape=X_train_lstm.shape[1:], epochs=50, batch_size=32,  verbose=0)\n",
    "start = time.time()\n",
    "best_slstm.fit(X_train_lstm, y_train)\n",
    "elapsed_slstm_test = (time.time() - start)\n",
    "print('r2_score for training set:', r2_score(y_train, best_slstm.predict(X_train_lstm)))\n",
    "print('r2_score for testing set:', r2_score(y_test, best_slstm.predict(X_test_lstm)))\n",
    "print(\"Stack LSTM took %.2f seconds for test.\" % (elapsed_slstm_test))\n",
    "slstm_test_pred = {}\n",
    "for key, X in X_test_dict.items():\n",
    "    X = np.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
    "    slstm_test_pred[key] = manual_descaling(best_slstm.predict(X), stress_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ea5942b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this code to skip hyperparameter tuning and training. my_model_final.h5 contains the trained model. \n",
    "#best_slstm.model_.save('lstm_model.h5')\n",
    "#from keras.models import load_model\n",
    "#best_slstm = load_model('lstm_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f845c247",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cadc1a",
   "metadata": {},
   "source": [
    "### Training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a2c43f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make the predictions for each training flow curve\n",
    "slstm_train_pred_stress = {}\n",
    "\n",
    "for key, X in X_train_dict.items():\n",
    "    X = np.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
    "    slstm_train_pred_stress[key] = manual_descaling(best_slstm.predict(X)[:,0], stress_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf58e7e",
   "metadata": {},
   "source": [
    "#### Stress predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c82e738-642d-4b86-a9af-9d1e5b7eeb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "plt.plot(flows['e4_298K']['Strain'][::15], flows['e4_298K']['Normalized Stress'][::15], 'o', label='298 K', color='red', alpha=1.0)\n",
    "plt.plot(flows['e4_298K']['Strain'], slstm_train_pred_stress['e4_298K'][:,], label='298 K Prediction', color='red', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "plt.plot(flows['e4_373K']['Strain'][::20], flows['e4_373K']['Normalized Stress'][::20], 'o', label='373 K', color='blue', alpha=1.0)\n",
    "plt.plot(flows['e4_373K']['Strain'], slstm_train_pred_stress['e4_373K'][:,], label='373 K Prediction', color='blue', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "plt.plot(flows['e4_573K']['Strain'][::15], flows['e4_573K']['Normalized Stress'][::15], 'o', label='573 K', color='green', alpha=1.0)\n",
    "plt.plot(flows['e4_573K']['Strain'], slstm_train_pred_stress['e4_573K'][:,], label='573 K Prediction', color='green', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "plt.plot(flows['e4_673K']['Strain'][::20], flows['e4_673K']['Normalized Stress'][::20], 'o', label='673 K', color='orange', alpha=1.0)\n",
    "plt.plot(flows['e4_673K']['Strain'], slstm_train_pred_stress['e4_673K'][:,], label='673 K Prediction', color='orange', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "plt.gca().add_artist(plt.legend(loc='best', fontsize='14'))\n",
    "plt.xlabel('True strain, -', fontsize='14')    #Name x label\n",
    "plt.ylabel('Normalized stress, -', fontsize='14')    #Name y label\n",
    "\n",
    "plt.xticks(fontsize='14')\n",
    "plt.yticks(fontsize='14')\n",
    "plt.xlim(xmin = 0)\n",
    "plt.ylim(0.6, 2)\n",
    "plt.title('Strain rates 0.0001 /s', fontweight='bold', fontsize='14')\n",
    "plt.savefig('FC_Train_0.0001.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5f2c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "#plt.plot(flows['e3']['Strain'][::20], flows['e3']['Normalized Stress'][::20], '.', label='298 K', color='red', alpha=1.0, markersize=10)\n",
    "#plt.plot(flows['e3']['Strain'], slstm_train_pred_stress['e3'][:,], label='298 K Prediction', color='red', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "plt.plot(flows['e3_373K']['Strain'][::20], flows['e3_373K']['Normalized Stress'][::20], 'o', label='373 K', color='red', alpha=1.0)\n",
    "plt.plot(flows['e3_373K']['Strain'], slstm_train_pred_stress['e3_373K'][:,], label='373 K Prediction', color='red', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "plt.plot(flows['e3_473K']['Strain'][::20], flows['e3_473K']['Normalized Stress'][::20], 'o', label='473 K', color='blue', alpha=1.0)\n",
    "plt.plot(flows['e3_473K']['Strain'], slstm_train_pred_stress['e3_473K'][:,], label='473 K Prediction', color='blue', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "plt.plot(flows['e3_573K']['Strain'][::20], flows['e3_573K']['Normalized Stress'][::20], 'o', label='573 K', color='green', alpha=1.0)\n",
    "plt.plot(flows['e3_573K']['Strain'], slstm_train_pred_stress['e3_573K'][:,], label='573 K Prediction', color='green', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "plt.plot(flows['e3_673K']['Strain'][::20], flows['e3_673K']['Normalized Stress'][::20], 'o', label='673 K', color='orange', alpha=1.0)\n",
    "plt.plot(flows['e3_673K']['Strain'], slstm_train_pred_stress['e3_673K'][:,], label='673 K Prediction', color='orange', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "plt.gca().add_artist(plt.legend(loc='best', fontsize='14'))\n",
    "plt.xlabel('True strain, -', fontsize='14')    #Name x label\n",
    "plt.ylabel('Normalized stress, -', fontsize='14')    #Name y label\n",
    "\n",
    "plt.xticks(fontsize='14')\n",
    "plt.yticks(fontsize='14')\n",
    "plt.xlim(xmin = 0)\n",
    "plt.ylim(0.6, 2)\n",
    "plt.title('Strain rates 0.001 /s', fontweight='bold', fontsize='14')\n",
    "plt.savefig('FC_Train_0.001.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b2afd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "plt.plot(flows['e2_298K']['Strain'][::4], flows['e2_298K']['Normalized Stress'][::4], 'o', label='298 K', color='red', alpha=1.0)\n",
    "plt.plot(flows['e2_298K']['Strain'], slstm_train_pred_stress['e2_298K'][:,], label='298 K Prediction', color='red', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "#plt.plot(flows['e2_373K']['Strain'][::20], flows['e2_373K']['Normalized Stress'][::20], '.', label='373 K', color='blue', alpha=1.0, markersize=10)\n",
    "#plt.plot(flows['e2_373K']['Strain'], slstm_train_pred_stress['e2_373K'][:,], label='373 K Prediction', color='blue', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "plt.plot(flows['e2_473K']['Strain'][::20], flows['e2_473K']['Normalized Stress'][::20], 'o', label='473 K', color='blue', alpha=1.0)\n",
    "plt.plot(flows['e2_473K']['Strain'], slstm_train_pred_stress['e2_473K'][:,], label='473 K Prediction', color='blue', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "plt.plot(flows['e2_573K']['Strain'][::20], flows['e2_573K']['Normalized Stress'][::20], 'o', label='573 K', color='green', alpha=1.0)\n",
    "plt.plot(flows['e2_573K']['Strain'], slstm_train_pred_stress['e2_573K'][:,], label='573 K Prediction', color='green', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "plt.plot(flows['e2_673K']['Strain'][::20], flows['e2_673K']['Normalized Stress'][::20], 'o', label='673 K', color='orange', alpha=1.0)\n",
    "plt.plot(flows['e2_673K']['Strain'], slstm_train_pred_stress['e2_673K'][:,], label='673 K Prediction', color='orange', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "plt.gca().add_artist(plt.legend(loc='best', fontsize='14'))\n",
    "plt.xlabel('True strain, -', fontsize='14')    #Name x label\n",
    "plt.ylabel('Normalized stress, -', fontsize='14')    #Name y label\n",
    "\n",
    "plt.xticks(fontsize='14')\n",
    "plt.yticks(fontsize='14')\n",
    "plt.xlim(xmin = 0)\n",
    "plt.ylim(0.6, 2)\n",
    "plt.title('Strain rates 0.01 /s', fontweight='bold', fontsize='14')\n",
    "plt.savefig('FC_Train_0.01.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef36332e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "plt.plot(flows['e1_298K']['Strain'][::2], flows['e1_298K']['Normalized Stress'][::2], 'o', label='298 K', color='red', alpha=1.0)\n",
    "plt.plot(flows['e1_298K']['Strain'], slstm_train_pred_stress['e1_298K'], label='298 K Prediction', color='red', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "plt.plot(flows['e1_373K']['Strain'][::2], flows['e1_373K']['Normalized Stress'][::2], 'o', label='373 K', color='blue', alpha=1.0)\n",
    "plt.plot(flows['e1_373K']['Strain'], slstm_train_pred_stress['e1_373K'], label='373 K Prediction', color='blue', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "plt.plot(flows['e1_473K']['Strain'][::2], flows['e1_473K']['Normalized Stress'][::2], 'o', label='473 K', color='green', alpha=1.0)\n",
    "plt.plot(flows['e1_473K']['Strain'], slstm_train_pred_stress['e1_473K'], label='473 K Prediction', color='green', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "#plt.plot(flows['e1_573K']['Strain'][::2], flows['e1_573K']['Normalized Stress'][::2], '.', label='573 K', color='green', alpha=1.0, markersize=10)\n",
    "#plt.plot(flows['e1_573K']['Strain'], slstm_train_pred_stress['e1_573K'], label='573 K Prediction', color='green', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "plt.plot(flows['e1_673K']['Strain'][::2], flows['e1_673K']['Normalized Stress'][::2], 'o', label='673 K', color='orange', alpha=1.0)\n",
    "plt.plot(flows['e1_673K']['Strain'], slstm_train_pred_stress['e1_673K'][:,], label='673 K Prediction', color='orange', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "plt.gca().add_artist(plt.legend(loc='best', fontsize='14'))\n",
    "plt.xlabel('True strain, -', fontsize='14')    #Name x label\n",
    "plt.ylabel('Normalized stress, -', fontsize='14')    #Name y label\n",
    "\n",
    "plt.xticks(fontsize='14')\n",
    "plt.yticks(fontsize='14')\n",
    "plt.xlim(xmin = 0)\n",
    "plt.ylim(0.6, 2)\n",
    "plt.title('Strain rates 0.1 /s', fontweight='bold', fontsize='14')\n",
    "plt.savefig('FC_Train_0.1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ca1006",
   "metadata": {},
   "source": [
    "### Testing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61b4e7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slstm_test_pred_stress = {}\n",
    "#slstm_test_pred_temp = {}\n",
    "for key, X in X_test_dict.items():\n",
    "    X = np.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
    "    slstm_test_pred_stress[key] = manual_descaling(best_slstm.predict(X)[:,0], stress_range)\n",
    "    #slstm_test_pred_temp[key] = manual_descaling(best_slstm.predict(X)[:,1], delT_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37649bd9",
   "metadata": {},
   "source": [
    "#### Stress predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f62824c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "plt.plot(flows['e4_473K']['Strain'][::20], flows['e4_473K']['Normalized Stress'][::20], 'o', label='473 K', color='red', alpha=1.0)\n",
    "plt.plot(flows['e4_473K']['Strain'], slstm_test_pred_stress['e4_473K'][:,], label='473 K Prediction', color='red', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "plt.gca().add_artist(plt.legend(loc='best', fontsize='14'))\n",
    "plt.xlabel('True strain, -', fontsize='14')    #Name x label\n",
    "plt.ylabel('Normalized stress, -', fontsize='14')    #Name y label\n",
    "\n",
    "plt.xticks(fontsize='14')\n",
    "plt.yticks(fontsize='14')\n",
    "plt.xlim(xmin = 0)\n",
    "plt.ylim(0.6, 2)\n",
    "plt.title('Strain rates 0.0001 /s', fontweight='bold',fontsize='14')\n",
    "plt.savefig('FC_Train_0.0001.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b201c7-760e-41e1-835e-1c61ea7d7173",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "plt.plot(flows['e3_298K']['Strain'][::10], flows['e3_298K']['Normalized Stress'][::10], 'o', label='298 K', color='red', alpha=1.0)\n",
    "plt.plot(flows['e3_298K']['Strain'], slstm_test_pred_stress['e3_298K'][:,], label='298 K Prediction', color='red', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "#plt.plot(flows['e3_473K']['Strain'][::20], flows['e3_473K']['Stress'][::20], '.', label='473 K', color='green', alpha=1.0, markersize=10)\n",
    "#plt.plot(flows['e3_473K']['Strain'], slstm_test_pred_stress['e3_473K'][:,], label='473 K Prediction', color='green', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "#plt.plot(flows['e3_673K']['Strain'][::20], flows['e3_673K']['Stress'][::20], '.', label='673 K', color='blue', alpha=1.0, markersize=10)\n",
    "#plt.plot(flows['e3_673K']['Strain'], slstm_test_pred_stress['e3_673K'][:,], label='673 K Prediction', color='blue', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "plt.gca().add_artist(plt.legend(loc='best', fontsize='14'))\n",
    "plt.xlabel('True strain, -', fontsize='14')    #Name x label\n",
    "plt.ylabel('Normalized stress, -', fontsize='14')    #Name y label\n",
    "\n",
    "plt.xticks(fontsize='14')\n",
    "plt.yticks(fontsize='14')\n",
    "plt.xlim(xmin = 0)\n",
    "plt.ylim(0.6, 2)\n",
    "plt.title('Strain rates 0.001 /s', fontweight='bold', fontsize='14')\n",
    "plt.savefig('FC_Train_0.001.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5f8e37-6345-4349-88b5-b05ae6e72e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "plt.plot(flows['e2_373K']['Strain'][::20], flows['e2_373K']['Normalized Stress'][::20], 'o', label='373 K', color='red', alpha=1.0)\n",
    "plt.plot(flows['e2_373K']['Strain'], slstm_test_pred_stress['e2_373K'][:,], label='373 K Prediction', color='red', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "#plt.plot(flows['e2_573K']['Strain'][::20], flows['e2_573K']['Stress'][::20], '.', label='573 K', color='green', alpha=1.0, markersize=10)\n",
    "#plt.plot(flows['e2_573K']['Strain'], slstm_test_pred_stress['e2_573K'][:,], label='573 K Prediction', color='green', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "#plt.plot(flows['e2_673K']['Strain'][::20], flows['e2_673K']['Normalized Stress'][::20], '.', label='673 K', color='blue', alpha=1.0, markersize=10)\n",
    "#plt.plot(flows['e2_673K']['Strain'], slstm_test_pred_stress['e2_673K'][:,], label='673 K Prediction', color='blue', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "plt.gca().add_artist(plt.legend(loc='best', fontsize='14'))\n",
    "plt.xlabel('True strain, -', fontsize='14')    #Name x label\n",
    "plt.ylabel('Normalized stress, -', fontsize='14')    #Name y label\n",
    "\n",
    "plt.xticks(fontsize='14')\n",
    "plt.yticks(fontsize='14')\n",
    "plt.xlim(xmin = 0)\n",
    "plt.ylim(0.6, 2)\n",
    "plt.title('Strain rates 0.01 /s', fontweight='bold', fontsize='14')\n",
    "plt.savefig('FC_Train_0.01.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd078ac6-61f7-4c27-abb2-e453b1617b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "#plt.plot(flows['e1']['Strain'][::5], flows['e1']['Stress'][::5], '.', label='298 K', color='red', alpha=1.0, markersize=10)\n",
    "#plt.plot(flows['e1']['Strain'], slstm_test_pred_stress['e1'][:,], label='298 K Prediction', color='red', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "#plt.plot(flows['e1_373K']['Strain'][::5], flows['e1_373K']['Stress'][::5], '.', label='373 K', color='blue', alpha=1.0, markersize=10)\n",
    "#plt.plot(flows['e1_373K']['Strain'], slstm_test_pred_stress['e1_373K'][:,], label='373 K Prediction', color='blue', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "#plt.plot(flows['e1_473K']['Strain'][::2], flows['e1_473K']['Stress'][::2], '.', label='473 K', color='green', alpha=1.0, markersize=10)\n",
    "#plt.plot(flows['e1_473K']['Strain'], slstm_test_pred_stress['e1_473K'][:,], label='473 K Prediction', color='green', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "plt.plot(flows['e1_573K']['Strain'][::2], flows['e1_573K']['Normalized Stress'][::2], 'o', label='573 K', color='red', alpha=1.0)\n",
    "plt.plot(flows['e1_573K']['Strain'], slstm_test_pred_stress['e1_573K'][:,], label='573 K Prediction', color='red', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "#plt.plot(flows['e1_673K']['Strain'][::2], flows['e1_673K']['Stress'][::2], '.', label='673 K', color='blue', alpha=1.0, markersize=10)\n",
    "#plt.plot(flows['e1_673K']['Strain'], slstm_test_pred_stress['e1_673K'][:,], label='673 K Prediction', color='blue', alpha=1.0, linewidth=2.5)\n",
    "\n",
    "plt.gca().add_artist(plt.legend(loc='best', fontsize='14'))\n",
    "plt.xlabel('True strain, -', fontsize='14')    #Name x label\n",
    "plt.ylabel('Normalized stress, -', fontsize='14')    #Name y label\n",
    "\n",
    "plt.xticks(fontsize='14')\n",
    "plt.yticks(fontsize='14')\n",
    "plt.xlim(xmin = 0)\n",
    "plt.ylim(0.6, 2)\n",
    "plt.title('Strain rates 0.1 /s', fontweight='bold', fontsize='14')\n",
    "plt.savefig('FC_Train_0.1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eade3a4-1fc0-4c7c-a141-ccc5dcbf9343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Load the data\n",
    "file_path = 'experiment_data_lstm.csv'  # Replace with your file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Get unique strain rates\n",
    "strain_rates = data['Strain Rate'].unique()\n",
    "\n",
    "# Loop through each strain rate and create a smooth 3D plot\n",
    "for strain_rate in strain_rates:\n",
    "    # Filter the data for the current strain rate\n",
    "    filtered_data = data[data['Strain Rate'] == strain_rate]\n",
    "\n",
    "    # Prepare the data\n",
    "    strain = filtered_data['Strain'].values\n",
    "    temperature = filtered_data['Temperature'].values\n",
    "    normalized_stress = filtered_data['Stress'].values\n",
    "\n",
    "    # Create a higher-resolution grid for smooth interpolation\n",
    "    strain_linspace = np.linspace(min(strain), max(strain), 100)\n",
    "    temp_linspace = np.linspace(min(temperature), max(temperature), 100)\n",
    "    strain_grid, temp_grid = np.meshgrid(strain_linspace, temp_linspace)\n",
    "\n",
    "    # Interpolate the normalized stress data to the high-res grid\n",
    "    normalized_stress_grid = griddata(\n",
    "        points=(strain, temperature),\n",
    "        values=normalized_stress,\n",
    "        xi=(strain_grid, temp_grid),\n",
    "        method='cubic'  # Smoother interpolation\n",
    "    )\n",
    "\n",
    "    # Plot the 3D surface\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Create the surface plot\n",
    "    surf = ax.plot_surface(temp_grid, strain_grid, normalized_stress_grid, cmap='viridis', edgecolor='none')\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_xlabel('Temperature (K)', fontsize=12)\n",
    "    ax.set_ylabel('Strain (-)', fontsize=12)\n",
    "    ax.set_zlabel('Stress (-)', fontsize=12)\n",
    "    ax.set_title(f'Normalized Stress vs. Strain and Temperature\\nStrain Rate: {strain_rate} /s', fontsize=14)\n",
    "\n",
    "    # Add a color bar\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=10)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62126fa8-72db-4579-a07e-c59c2887e2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
